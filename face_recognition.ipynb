{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import cv2\n",
    "import dlib\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import os\n",
    "import ntpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_predictor_68_point = dlib.shape_predictor(\"pretrained_model/shape_predictor_68_face_landmarks.dat\")\n",
    "pose_predictor_5_point = dlib.shape_predictor(\"pretrained_model/shape_predictor_5_face_landmarks.dat\")\n",
    "face_encoder = dlib.face_recognition_model_v1(\"pretrained_model/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, face_locations): \n",
    "    coord_faces = []\n",
    "    for face in face_locations:\n",
    "        rect = face.top(), face.right(), face.bottom(), face.left()\n",
    "        coord_face = max(rect[0], 0), min(rect[1], image.shape[1]), min(rect[2], image.shape[0]), max(rect[3], 0)\n",
    "        coord_faces.append(coord_face)\n",
    "    return coord_faces\n",
    "\n",
    "\n",
    "def encode_face(image): \n",
    "    face_locations = face_detector(image, 1)\n",
    "    face_encodings_list = []\n",
    "    landmarks_list = []\n",
    "    for face_location in face_locations:\n",
    "        # DETECT FACES\n",
    "        shape = pose_predictor_68_point(image, face_location)\n",
    "        face_encodings_list.append(np.array(face_encoder.compute_face_descriptor(image, shape, num_jitters=1)))\n",
    "        # GET LANDMARKS\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        landmarks_list.append(shape)\n",
    "    face_locations = transform(image, face_locations)\n",
    "    return face_encodings_list, face_locations, landmarks_list\n",
    "\n",
    "\n",
    "def face_recognition(frame, known_face_encodings, known_face_names): \n",
    "    rgb_small_frame = frame[:, :, ::-1]\n",
    "    # ENCODING FACE\n",
    "    face_encodings_list, face_locations_list, landmarks_list = encode_face(rgb_small_frame)\n",
    "    face_names = []\n",
    "    for face_encoding in face_encodings_list:\n",
    "        if len(face_encoding) == 0:\n",
    "            return np.empty((0))\n",
    "        # CHECK DISTANCE BETWEEN KNOWN FACES AND FACES DETECTED\n",
    "        vectors = np.linalg.norm(known_face_encodings - face_encoding, axis=1)\n",
    "        tolerance = 0.6\n",
    "        result = []\n",
    "        for vector in vectors:\n",
    "            if vector <= tolerance:\n",
    "                result.append(True)\n",
    "            else:\n",
    "                result.append(False)\n",
    "        if True in result:\n",
    "            first_match_index = result.index(True)\n",
    "            name = known_face_names[first_match_index]\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        face_names.append(name)\n",
    "\n",
    "    for (top, right, bottom, left), name in zip(face_locations_list, face_names):\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame, (left, bottom - 30), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "        cv2.putText(frame, name, (left + 2, bottom - 2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "\n",
    "    for shape in landmarks_list:\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(frame, (x, y), 1, (255, 0, 255), -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    face_to_encode_path = Path(\"H:/Desktop/face_recognition/src\")\n",
    "    files = [file_ for file_ in face_to_encode_path.rglob('*.jpg')]\n",
    "\n",
    "    for file_ in face_to_encode_path.rglob('*.png'):\n",
    "        files.append(file_)\n",
    "    if len(files)==0:\n",
    "        raise ValueError('No faces detect in the directory: {}'.format(face_to_encode_path))\n",
    "    known_face_names = [os.path.splitext(ntpath.basename(file_))[0] for file_ in files]\n",
    "\n",
    "    known_face_encodings = []\n",
    "    for file_ in files:\n",
    "        image = PIL.Image.open(file_)\n",
    "        image = np.array(image)\n",
    "        face_encoded = encode_face(image)[0][0]\n",
    "        known_face_encodings.append(face_encoded)\n",
    "\n",
    "    ##starting camera\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    video_capture.set(cv2.CAP_PROP_FPS, 30)\n",
    "    bool = True\n",
    "    while bool:\n",
    "        ret, frame = video_capture.read()\n",
    "        face_recognition(frame, known_face_encodings, known_face_names)\n",
    "        cv2.imshow('Face_Recognition', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            video_capture.release()\n",
    "            bool = False\n",
    "            break\n",
    "    \n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
